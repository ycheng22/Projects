{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a href=\"https://cognitiveclass.ai\"><img src = \"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/Logos/organization_logo/organization_logo.png\" width = 400> </a>\n",
    "\n",
    "<h1 align=center><font size = 5>Pre-Trained Models</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In this lab, you will learn how to leverage pre-trained models to build image classifiers instead of building a model from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Table of Contents\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "\n",
    "<font size = 3> \n",
    "    \n",
    "1. <a href=\"#item31\">Import Libraries and Packages</a>\n",
    "2. <a href=\"#item32\">Download Data</a>  \n",
    "3. <a href=\"#item33\">Define Global Constants</a>  \n",
    "4. <a href=\"#item34\">Construct ImageDataGenerator Instances</a>  \n",
    "5. <a href=\"#item35\">Compile and Fit Model</a>\n",
    "\n",
    "</font>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item31'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Import Libraries and Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Let's start the lab by importing the libraries that we will be using in this lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "First, we will import the ImageDataGenerator module since we will be leveraging it to train our model in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In this lab, we will be using the Keras library to build an image classifier, so let's download the Keras library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Finally, we will be leveraging the ResNet50 model to build our classifier, so let's download it as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from keras.applications import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item32'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "For your convenience, I have placed the data on a server which you can retrieve easily using the **wget** command. So let's run the following line of code to get the data. Given the large size of the image dataset, it might take some time depending on your internet speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "## get the data\n",
    "#!wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/concrete_data_week3.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "And now if you check the left directory pane, you should see the zipped file *concrete_data_week3.zip* appear. So, let's go ahead and unzip the file to access the images. Given the large number of images in the dataset, this might take a couple of minutes, so please be patient, and wait until the code finishes running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!unzip concrete_data_week3.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###run on local notebook\n",
    "\n",
    "# from io import BytesIO\n",
    "# from urllib.request import urlopen\n",
    "# from zipfile import ZipFile\n",
    "# zipurl = 'https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/concrete_data_week3.zip'\n",
    "# with urlopen(zipurl) as zipresp:\n",
    "#     with ZipFile(BytesIO(zipresp.read())) as zfile:\n",
    "#         zfile.extractall() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now, you should see the folder *concrete_data_week3* appear in the left pane. If you open this folder by double-clicking on it, you will find that it contains two folders: *train* and *valid*. And if you explore these folders, you will find that each contains two subfolders: *positive* and *negative*. These are the same folders that we saw in the labs in the previous modules of this course, where *negative* is the negative class and it represents the concrete images with no cracks and *positive* is the positive class and it represents the concrete images with cracks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "**Important Note**: There are thousands and thousands of images in each folder, so please don't attempt to double click on the *negative* and *positive* folders. This may consume all of your memory and you may end up with a **50*** error. So please **DO NOT DO IT**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item33'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Define Global Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Here, we will define constants that we will be using throughout the rest of the lab. \n",
    "\n",
    "1. We are obviously dealing with two classes, so *num_classes* is 2. \n",
    "2. The ResNet50 model was built and trained using images of size (224 x 224). Therefore, we will have to resize our images from (227 x 227) to (224 x 224).\n",
    "3. We will training and validating the model using batches of 100 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "\n",
    "image_resize = 224\n",
    "\n",
    "batch_size_training = 100\n",
    "batch_size_validation = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item34'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Construct ImageDataGenerator Instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In order to instantiate an ImageDataGenerator instance, we will set the **preprocessing_function** argument to *preprocess_input* which we imported from **keras.applications.resnet50** in order to preprocess our images the same way the images used to train ResNet50 model were processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Next, we will use the *flow_from_directory* method to get the training images as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30001 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = data_generator.flow_from_directory(\n",
    "    'concrete_data_week3/train',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_training,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "**Your Turn**: Use the *flow_from_directory* method to get the validation images and assign the result to **validation_generator**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10001 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "## Type your answer here\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "    'concrete_data_week3/valid',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_training,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Double-click __here__ for the solution.\n",
    "<!-- The correct answer is:\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "    'concrete_data_week3/valid',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_validation,\n",
    "    class_mode='categorical')\n",
    "-->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item35'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Build, Compile and Fit Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In this section, we will start building our model. We will use the Sequential model class from Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Next, we will add the ResNet50 pre-trained model to out model. However, note that we don't want to include the top layer or the output layer of the pre-trained model. We actually want to define our own output layer and train it so that it is optimized for our image dataset. In order to leave out the output layer of the pre-trained model, we will use the argument *include_top* and set it to **False**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94658560/94653016 [==============================] - 82s 1us/step\n"
     ]
    }
   ],
   "source": [
    "model.add(ResNet50(\n",
    "    include_top=False,\n",
    "    pooling='avg',\n",
    "    weights='imagenet',\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Then, we will define our output layer as a **Dense** layer, that consists of two nodes and uses the **Softmax** function as the activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "You can access the model's layers using the *layers* attribute of our model object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.training.Model at 0x22a9d355b88>,\n",
       " <keras.layers.core.Dense at 0x22aae588608>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "You can see that our model is composed of two sets of layers. The first set is the layers pertaining to ResNet50 and the second set is a single layer, which is our Dense layer that we defined above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "You can access the ResNet50 layers by running the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x22a8de851c8>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x22a8de7afc8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a8de87308>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a8df56308>,\n",
       " <keras.layers.core.Activation at 0x22a8df560c8>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x22a8e6348c8>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x22a91caeb88>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a91d06708>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a91d0fe48>,\n",
       " <keras.layers.core.Activation at 0x22a91d0fc08>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a91d11948>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a91d26f88>,\n",
       " <keras.layers.core.Activation at 0x22a91d3acc8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a91d636c8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a91db7708>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a91d79208>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a91dd9488>,\n",
       " <keras.layers.merge.Add at 0x22a91dcf908>,\n",
       " <keras.layers.core.Activation at 0x22a91e04988>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a91e0c748>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a91e5bc88>,\n",
       " <keras.layers.core.Activation at 0x22a91e5bb88>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a91e63bc8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a91e83908>,\n",
       " <keras.layers.core.Activation at 0x22a91e8f6c8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a91eb58c8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a920d7f08>,\n",
       " <keras.layers.merge.Add at 0x22a920f16c8>,\n",
       " <keras.layers.core.Activation at 0x22a92118808>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a92118c08>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a92167e88>,\n",
       " <keras.layers.core.Activation at 0x22a92167f08>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a9216c608>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a92195a48>,\n",
       " <keras.layers.core.Activation at 0x22a92195588>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a921c1148>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a921ea8c8>,\n",
       " <keras.layers.merge.Add at 0x22a921ea6c8>,\n",
       " <keras.layers.core.Activation at 0x22a92216348>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a92216988>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a92272b08>,\n",
       " <keras.layers.core.Activation at 0x22a92272948>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a92272988>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a92283e88>,\n",
       " <keras.layers.core.Activation at 0x22a9229a3c8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a922c4148>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a9271ddc8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a926ea1c8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a92742188>,\n",
       " <keras.layers.merge.Add at 0x22a92747fc8>,\n",
       " <keras.layers.core.Activation at 0x22a92775a08>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a9277dfc8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a927c3d08>,\n",
       " <keras.layers.core.Activation at 0x22a927cc488>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a927d4e08>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a927f1d48>,\n",
       " <keras.layers.core.Activation at 0x22a927fe288>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a92824d88>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a92845ec8>,\n",
       " <keras.layers.merge.Add at 0x22a9284f288>,\n",
       " <keras.layers.core.Activation at 0x22a92871c88>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a9287bd88>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a928c6e88>,\n",
       " <keras.layers.core.Activation at 0x22a928c6f08>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a928cef08>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a928f2308>,\n",
       " <keras.layers.core.Activation at 0x22a928f7888>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a9291f988>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a9294e848>,\n",
       " <keras.layers.merge.Add at 0x22a9296de48>,\n",
       " <keras.layers.core.Activation at 0x22a929736c8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a929730c8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a929c3e48>,\n",
       " <keras.layers.core.Activation at 0x22a929c3f88>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a929c9848>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a929f1cc8>,\n",
       " <keras.layers.core.Activation at 0x22a929f6fc8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a92a24e08>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a92a46a48>,\n",
       " <keras.layers.merge.Add at 0x22a92a49fc8>,\n",
       " <keras.layers.core.Activation at 0x22a93280a08>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a93286e08>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a932d5c08>,\n",
       " <keras.layers.core.Activation at 0x22a932d5b08>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a932d56c8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a932fa888>,\n",
       " <keras.layers.core.Activation at 0x22a93327f48>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a9332e288>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a95372288>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a94313248>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a953946c8>,\n",
       " <keras.layers.merge.Add at 0x22a95394188>,\n",
       " <keras.layers.core.Activation at 0x22a953bfe88>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a953bfb48>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a95418b08>,\n",
       " <keras.layers.core.Activation at 0x22a95418a08>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a9541fd88>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a9543db88>,\n",
       " <keras.layers.core.Activation at 0x22a95469f08>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a954709c8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a954897c8>,\n",
       " <keras.layers.merge.Add at 0x22a954bcf08>,\n",
       " <keras.layers.core.Activation at 0x22a954c4688>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a954d6108>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a95512e88>,\n",
       " <keras.layers.core.Activation at 0x22a95512f88>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a95519508>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a95542648>,\n",
       " <keras.layers.core.Activation at 0x22a95543c08>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a9556c9c8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a95596888>,\n",
       " <keras.layers.merge.Add at 0x22a95596608>,\n",
       " <keras.layers.core.Activation at 0x22a955be708>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a955be808>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a95616548>,\n",
       " <keras.layers.core.Activation at 0x22a95616388>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a9561ff48>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a9563b108>,\n",
       " <keras.layers.core.Activation at 0x22a956472c8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a95670e08>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a9568ef48>,\n",
       " <keras.layers.merge.Add at 0x22a9569c2c8>,\n",
       " <keras.layers.core.Activation at 0x22a977ebd08>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a978090c8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a97840f08>,\n",
       " <keras.layers.core.Activation at 0x22a97840e08>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a97848c88>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a9786c388>,\n",
       " <keras.layers.core.Activation at 0x22a97875948>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a9789b6c8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a978b1c48>,\n",
       " <keras.layers.merge.Add at 0x22a978c88c8>,\n",
       " <keras.layers.core.Activation at 0x22a978ef588>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a9790d1c8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a9793bfc8>,\n",
       " <keras.layers.core.Activation at 0x22a9793bd88>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a97944488>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a9796cc88>,\n",
       " <keras.layers.core.Activation at 0x22a97973e48>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a9799efc8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a979bfac8>,\n",
       " <keras.layers.merge.Add at 0x22a979bf9c8>,\n",
       " <keras.layers.core.Activation at 0x22a979e94c8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a979f1fc8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a97a3bc88>,\n",
       " <keras.layers.core.Activation at 0x22a97a3bb88>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a97a45bc8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a97a65908>,\n",
       " <keras.layers.core.Activation at 0x22a97a6f6c8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a97a9a8c8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a9bd0b8c8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a97aaaf08>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a9bd2ae08>,\n",
       " <keras.layers.merge.Add at 0x22a9bd2e208>,\n",
       " <keras.layers.core.Activation at 0x22a9bd5ae08>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a9bd606c8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a9bdb2c08>,\n",
       " <keras.layers.core.Activation at 0x22a9bdb2b08>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a9bdb26c8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a9bdd8888>,\n",
       " <keras.layers.core.Activation at 0x22a9be03f48>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a9be0b288>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a9be1c248>,\n",
       " <keras.layers.merge.Add at 0x22a9be55f48>,\n",
       " <keras.layers.core.Activation at 0x22a9be5c788>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a9be5cd88>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a9beade88>,\n",
       " <keras.layers.core.Activation at 0x22a9beadf08>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a9ce84608>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a9ceaba88>,\n",
       " <keras.layers.core.Activation at 0x22a9ceab5c8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22a9ced5188>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22a9cef1088>,\n",
       " <keras.layers.merge.Add at 0x22a9d313d08>,\n",
       " <keras.layers.core.Activation at 0x22a9d339a88>,\n",
       " <keras.layers.pooling.GlobalAveragePooling2D at 0x22a9be7dd88>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Since the ResNet50 model has already been trained, then we want to tell our model not to bother with training the ResNet part, but to train only our dense output layer. To do that, we run the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "And now using the *summary* attribute of the model, we can see how many parameters we will need to optimize in order to train the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 2048)              23587712  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 4098      \n",
      "=================================================================\n",
      "Total params: 23,591,810\n",
      "Trainable params: 4,098\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Next we compile our model using the **adam** optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Before we are able to start the training process, with an ImageDataGenerator, we will need to define how many steps compose an epoch. Typically, that is the number of images divided by the batch size. Therefore, we define our steps per epoch as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "steps_per_epoch_training = len(train_generator)\n",
    "steps_per_epoch_validation = len(validation_generator)\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Finally, we are ready to start training our model. Unlike a conventional deep learning training were data is not streamed from a directory, with an ImageDataGenerator where data is augmented in batches, we use the **fit_generator** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "301/301 [==============================] - 9824s 33s/step - loss: 0.0437 - accuracy: 0.9871 - val_loss: 0.1320 - val_accuracy: 0.8988\n",
      "Epoch 2/2\n",
      "301/301 [==============================] - 10097s 34s/step - loss: 0.0127 - accuracy: 0.9976 - val_loss: 4.8099 - val_accuracy: 0.7461\n"
     ]
    }
   ],
   "source": [
    "fit_history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch_training,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=steps_per_epoch_validation,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now that the model is trained, you are ready to start using it to classify images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Since training can take a long time when building deep learning models, it is always a good idea to save your model once the training is complete if you believe you will be using the model again later. You will be using this model in the next module, so go ahead and save your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.save('classifier_resnet_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('classifier_resnet_model2.h5', include_optimizer=False) #this is from https://stackoverflow.com/a/49199132/7133888"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now, you should see the model file *classifier_resnet_model.h5* apprear in the left directory pane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Thank you for completing this lab!\n",
    "\n",
    "This notebook was created by Alex Aklson. I hope you found this lab interesting and educational."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "This notebook is part of a course on **Coursera** called *AI Capstone Project with Deep Learning*. If you accessed this notebook outside the course, you can take this course online by clicking [here](https://cocl.us/DL0321EN_Coursera_Week3_LAB1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "Copyright &copy; 2020 [IBM Developer Skills Network](https://cognitiveclass.ai/?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu). This notebook and its source code are released under the terms of the [MIT License](https://bigdatauniversity.com/mit-license/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
